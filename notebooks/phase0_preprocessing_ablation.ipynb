{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bbb92de",
   "metadata": {},
   "source": [
    "# Phase 0: Preprocessing Ablation for Macro-F1\n",
    "\n",
    "Goal: quantify whether preprocessing improves macro-F1 before retraining heavy transformer models.\n",
    "\n",
    "Outputs:\n",
    "- `outputs/preprocessing_ablation_report.csv`\n",
    "- `outputs/preprocessing_examples.csv`\n",
    "- `outputs/train_cleaned_esg_normalized.csv`\n",
    "- `outputs/test_cleaned_esg_normalized.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0810e64f",
   "metadata": {},
   "source": [
    "## 1) Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed in Colab, uncomment:\n",
    "# !pip install -q pandas numpy scikit-learn iterative-stratification matplotlib\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "# Ensure local module import works from notebooks/\n",
    "if Path('.').resolve().name == 'notebooks':\n",
    "    sys.path.append(str(Path('..').resolve()))\n",
    "else:\n",
    "    sys.path.append(str(Path('.').resolve()))\n",
    "\n",
    "from src.text_preprocessing import PreprocessConfig, clean_text, build_ablation_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b756680",
   "metadata": {},
   "source": [
    "## 2) Configure Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a237f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['E', 'S', 'G', 'non_ESG']\n",
    "ID_COL = 'id'\n",
    "TEXT_COL = 'text'\n",
    "\n",
    "N_SPLITS = 5\n",
    "SEED = 42\n",
    "MAX_FEATURES = 120_000\n",
    "MIN_DF = 2\n",
    "\n",
    "if Path('data_set').exists():\n",
    "    ROOT = Path('.')\n",
    "elif Path('../data_set').exists():\n",
    "    ROOT = Path('..')\n",
    "else:\n",
    "    ROOT = Path('.')\n",
    "\n",
    "TRAIN_PATH = ROOT / 'data_set' / 'train.csv'\n",
    "TEST_PATH = ROOT / 'data_set' / 'test.csv'\n",
    "OUTPUT_DIR = ROOT / 'outputs'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('ROOT:', ROOT.resolve())\n",
    "print('TRAIN_PATH exists:', TRAIN_PATH.exists())\n",
    "print('TEST_PATH exists:', TEST_PATH.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df0295",
   "metadata": {},
   "source": [
    "## 3) Load or Create Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a690515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "assert all(col in train_df.columns for col in [ID_COL, TEXT_COL] + LABELS)\n",
    "assert all(col in test_df.columns for col in [ID_COL, TEXT_COL])\n",
    "\n",
    "train_df[TEXT_COL] = train_df[TEXT_COL].fillna('').astype(str)\n",
    "test_df[TEXT_COL] = test_df[TEXT_COL].fillna('').astype(str)\n",
    "\n",
    "print('Train shape:', train_df.shape)\n",
    "print('Test shape:', test_df.shape)\n",
    "print('\\nLabel prevalence:')\n",
    "print(train_df[LABELS].mean())\n",
    "\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5770dc",
   "metadata": {},
   "source": [
    "## 4) Implement Core Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbab70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(y_true, y_pred):\n",
    "    vals = [f1_score(y_true[:, i], y_pred[:, i], zero_division=0) for i in range(y_true.shape[1])]\n",
    "    return float(np.mean(vals)), vals\n",
    "\n",
    "\n",
    "def run_tfidf_cv(text_series, y, n_splits=5, seed=42):\n",
    "    cv = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    oof_prob = np.zeros((len(text_series), y.shape[1]), dtype=float)\n",
    "\n",
    "    for tr_idx, va_idx in cv.split(text_series.values, y):\n",
    "        x_tr = text_series.iloc[tr_idx].values\n",
    "        x_va = text_series.iloc[va_idx].values\n",
    "        y_tr = y[tr_idx]\n",
    "\n",
    "        vec = TfidfVectorizer(\n",
    "            lowercase=True,\n",
    "            strip_accents='unicode',\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=MIN_DF,\n",
    "            max_features=MAX_FEATURES,\n",
    "            sublinear_tf=True,\n",
    "        )\n",
    "        xtr = vec.fit_transform(x_tr)\n",
    "        xva = vec.transform(x_va)\n",
    "\n",
    "        clf = OneVsRestClassifier(\n",
    "            LogisticRegression(C=2.0, max_iter=2500, class_weight='balanced', solver='liblinear')\n",
    "        )\n",
    "        clf.fit(xtr, y_tr)\n",
    "        oof_prob[va_idx] = clf.predict_proba(xva)\n",
    "\n",
    "    y_pred = (oof_prob >= 0.5).astype(int)\n",
    "    macro, per_label = macro_f1(y, y_pred)\n",
    "    return macro, per_label, oof_prob\n",
    "\n",
    "\n",
    "y = train_df[LABELS].values.astype(int)\n",
    "configs = build_ablation_configs()\n",
    "rows = []\n",
    "examples = []\n",
    "\n",
    "for name, cfg in configs.items():\n",
    "    cleaned = train_df[TEXT_COL].apply(lambda t: clean_text(t, cfg))\n",
    "    macro, per_label, _ = run_tfidf_cv(cleaned, y, N_SPLITS, SEED)\n",
    "    rows.append({\n",
    "        'config': name,\n",
    "        'macro_f1': round(macro, 6),\n",
    "        **{f'f1_{LABELS[i]}': round(float(per_label[i]), 6) for i in range(len(LABELS))}\n",
    "    })\n",
    "\n",
    "    for i in range(3):\n",
    "        examples.append({\n",
    "            'config': name,\n",
    "            'id': int(train_df.iloc[i][ID_COL]),\n",
    "            'original': train_df.iloc[i][TEXT_COL],\n",
    "            'cleaned': cleaned.iloc[i]\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(rows).sort_values('macro_f1', ascending=False).reset_index(drop=True)\n",
    "examples_df = pd.DataFrame(examples)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f1cf4",
   "metadata": {},
   "source": [
    "## 5) Run Validation Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f33bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not results_df.empty\n",
    "assert set(['config', 'macro_f1']).issubset(results_df.columns)\n",
    "assert results_df['macro_f1'].between(0, 1).all()\n",
    "\n",
    "best_config_name = results_df.iloc[0]['config']\n",
    "best_cfg = configs[best_config_name]\n",
    "print('Best preprocessing config:', best_config_name)\n",
    "print(results_df[['config', 'macro_f1']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a2433",
   "metadata": {},
   "source": [
    "## 6) Visualize Key Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f72c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_df)\n",
    "\n",
    "display(examples_df.head(9))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(results_df['config'], results_df['macro_f1'])\n",
    "plt.title('Macro-F1 by Preprocessing Configuration')\n",
    "plt.ylabel('Macro-F1')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59288a92",
   "metadata": {},
   "source": [
    "## 7) Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb58bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train = train_df.copy()\n",
    "best_test = test_df.copy()\n",
    "\n",
    "best_train[TEXT_COL] = best_train[TEXT_COL].apply(lambda t: clean_text(t, best_cfg))\n",
    "best_test[TEXT_COL] = best_test[TEXT_COL].apply(lambda t: clean_text(t, best_cfg))\n",
    "\n",
    "report_path = OUTPUT_DIR / 'preprocessing_ablation_report.csv'\n",
    "examples_path = OUTPUT_DIR / 'preprocessing_examples.csv'\n",
    "train_clean_path = OUTPUT_DIR / f'train_cleaned_{best_config_name}.csv'\n",
    "test_clean_path = OUTPUT_DIR / f'test_cleaned_{best_config_name}.csv'\n",
    "\n",
    "results_df.to_csv(report_path, index=False)\n",
    "examples_df.to_csv(examples_path, index=False)\n",
    "best_train.to_csv(train_clean_path, index=False)\n",
    "best_test.to_csv(test_clean_path, index=False)\n",
    "\n",
    "print('Saved:')\n",
    "print(report_path)\n",
    "print(examples_path)\n",
    "print(train_clean_path)\n",
    "print(test_clean_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
