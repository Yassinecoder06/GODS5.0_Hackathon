{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7db0603",
   "metadata": {},
   "source": [
    "# Phase 2: DistilBERT Multi-Label Pipeline (Macro-F1 Focus)\n",
    "\n",
    "Colab-ready notebook for ESG multi-label classification with:\n",
    "- `MultilabelStratifiedKFold`\n",
    "- DistilBERT fine-tuning\n",
    "- Per-label threshold tuning for Macro-F1\n",
    "- Optional `non_ESG` consistency rule\n",
    "- Submission export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe546aa",
   "metadata": {},
   "source": [
    "## 1) Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed in Colab, uncomment:\n",
    "# !pip install -q transformers datasets accelerate iterative-stratification scikit-learn pandas numpy tqdm matplotlib\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print('Torch:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3312ee1a",
   "metadata": {},
   "source": [
    "## 2) Configure Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca8fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['E', 'S', 'G', 'non_ESG']\n",
    "ID_COL = 'id'\n",
    "TEXT_COL = 'text'\n",
    "\n",
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "MAX_LENGTH = 256\n",
    "N_SPLITS = 5\n",
    "LR = 2e-5\n",
    "TRAIN_BS = 16\n",
    "EVAL_BS = 32\n",
    "NUM_EPOCHS = 3\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "THRESHOLD_MIN = 0.05\n",
    "THRESHOLD_MAX = 0.95\n",
    "THRESHOLD_STEP = 0.01\n",
    "ENABLE_NON_ESG_RULE = True\n",
    "\n",
    "# Path auto-detection: works in local notebook folder or project root\n",
    "if Path('data_set').exists():\n",
    "    ROOT = Path('.')\n",
    "elif Path('../data_set').exists():\n",
    "    ROOT = Path('..')\n",
    "else:\n",
    "    ROOT = Path('.')\n",
    "\n",
    "TRAIN_PATH = ROOT / 'data_set' / 'train.csv'\n",
    "TEST_PATH = ROOT / 'data_set' / 'test.csv'\n",
    "SAMPLE_SUB_PATH = ROOT / 'data_set' / 'sample_submission.csv'\n",
    "OUTPUT_DIR = ROOT / 'outputs'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('ROOT:', ROOT.resolve())\n",
    "print('TRAIN_PATH exists:', TRAIN_PATH.exists())\n",
    "print('TEST_PATH exists:', TEST_PATH.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ab042",
   "metadata": {},
   "source": [
    "## 3) Load or Create Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "sample_sub_df = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "\n",
    "print('Train shape:', train_df.shape)\n",
    "print('Test shape:', test_df.shape)\n",
    "print('Sample submission shape:', sample_sub_df.shape)\n",
    "\n",
    "required_train_cols = [ID_COL, TEXT_COL] + LABELS\n",
    "missing_cols = [c for c in required_train_cols if c not in train_df.columns]\n",
    "assert len(missing_cols) == 0, f'Missing train columns: {missing_cols}'\n",
    "assert ID_COL in test_df.columns and TEXT_COL in test_df.columns\n",
    "\n",
    "train_df[TEXT_COL] = train_df[TEXT_COL].fillna('').astype(str)\n",
    "test_df[TEXT_COL] = test_df[TEXT_COL].fillna('').astype(str)\n",
    "\n",
    "y = train_df[LABELS].values.astype(np.float32)\n",
    "\n",
    "prevalence = train_df[LABELS].mean().sort_values(ascending=False)\n",
    "print('\\nLabel prevalence:')\n",
    "print(prevalence)\n",
    "\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae55829",
   "metadata": {},
   "source": [
    "## 4) Implement Core Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class ESGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length, labels=None):\n",
    "        self.texts = list(texts)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return item\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    scores = [f1_score(y_true[:, i], y_pred[:, i], zero_division=0) for i in range(y_true.shape[1])]\n",
    "    return float(np.mean(scores)), scores\n",
    "\n",
    "\n",
    "def tune_thresholds(y_true, y_prob, tmin=0.05, tmax=0.95, step=0.01):\n",
    "    grid = np.arange(tmin, tmax + 1e-12, step)\n",
    "    best = {}\n",
    "    for i, label in enumerate(LABELS):\n",
    "        best_t, best_f1 = 0.5, -1.0\n",
    "        for t in grid:\n",
    "            pred = (y_prob[:, i] >= t).astype(int)\n",
    "            f1 = f1_score(y_true[:, i], pred, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_t = float(t)\n",
    "        best[label] = round(best_t, 4)\n",
    "    return best\n",
    "\n",
    "\n",
    "def apply_thresholds(y_prob, thresholds):\n",
    "    y_pred = np.zeros_like(y_prob, dtype=int)\n",
    "    for i, label in enumerate(LABELS):\n",
    "        y_pred[:, i] = (y_prob[:, i] >= thresholds[label]).astype(int)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def apply_non_esg_rule(y_pred):\n",
    "    fixed = y_pred.copy()\n",
    "    esg_any = (fixed[:, 0] + fixed[:, 1] + fixed[:, 2]) > 0\n",
    "    fixed[esg_any, 3] = 0\n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b607d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mskf = MultilabelStratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "oof_prob = np.zeros((len(train_df), len(LABELS)), dtype=np.float32)\n",
    "test_prob_folds = []\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(mskf.split(train_df[TEXT_COL].values, y), start=1):\n",
    "    print(f'\\n===== Fold {fold}/{N_SPLITS} =====')\n",
    "\n",
    "    x_tr = train_df.iloc[tr_idx][TEXT_COL].tolist()\n",
    "    x_va = train_df.iloc[va_idx][TEXT_COL].tolist()\n",
    "    y_tr = y[tr_idx]\n",
    "    y_va = y[va_idx]\n",
    "\n",
    "    train_ds = ESGDataset(x_tr, tokenizer, MAX_LENGTH, y_tr)\n",
    "    valid_ds = ESGDataset(x_va, tokenizer, MAX_LENGTH, y_va)\n",
    "    test_ds = ESGDataset(test_df[TEXT_COL].tolist(), tokenizer, MAX_LENGTH, labels=None)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=len(LABELS),\n",
    "        problem_type='multi_label_classification'\n",
    "    )\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=str(OUTPUT_DIR / f'distilbert_fold_{fold}'),\n",
    "        learning_rate=LR,\n",
    "        per_device_train_batch_size=TRAIN_BS,\n",
    "        per_device_eval_batch_size=EVAL_BS,\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='no',\n",
    "        logging_steps=50,\n",
    "        report_to='none',\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        dataloader_num_workers=2,\n",
    "        remove_unused_columns=False,\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=valid_ds,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    va_logits = trainer.predict(valid_ds).predictions\n",
    "    te_logits = trainer.predict(test_ds).predictions\n",
    "\n",
    "    va_prob = sigmoid(va_logits)\n",
    "    te_prob = sigmoid(te_logits)\n",
    "\n",
    "    oof_prob[va_idx] = va_prob\n",
    "    test_prob_folds.append(te_prob)\n",
    "\n",
    "    fold_pred_default = (va_prob >= 0.5).astype(int)\n",
    "    fold_macro, fold_label_scores = macro_f1(y_va.astype(int), fold_pred_default)\n",
    "    fold_metrics.append({\n",
    "        'fold': fold,\n",
    "        'macro_f1@0.5': round(fold_macro, 6),\n",
    "        'label_f1@0.5': {LABELS[i]: round(float(fold_label_scores[i]), 6) for i in range(len(LABELS))}\n",
    "    })\n",
    "    print('Fold macro-F1 @0.5:', round(fold_macro, 6))\n",
    "\n",
    "    del model, trainer, train_ds, valid_ds, test_ds\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "test_prob = np.mean(np.stack(test_prob_folds, axis=0), axis=0)\n",
    "print('\\nFinished CV. OOF shape:', oof_prob.shape, ' Test prob shape:', test_prob.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0aa8b1",
   "metadata": {},
   "source": [
    "## 5) Run Validation Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_int = y.astype(int)\n",
    "\n",
    "thresholds = tune_thresholds(\n",
    "    y_true=y_true_int,\n",
    "    y_prob=oof_prob,\n",
    "    tmin=THRESHOLD_MIN,\n",
    "    tmax=THRESHOLD_MAX,\n",
    "    step=THRESHOLD_STEP\n",
    ")\n",
    "\n",
    "oof_pred = apply_thresholds(oof_prob, thresholds)\n",
    "test_pred = apply_thresholds(test_prob, thresholds)\n",
    "\n",
    "macro_base, per_label_base = macro_f1(y_true_int, oof_pred)\n",
    "print('Macro-F1 after threshold tuning:', round(macro_base, 6))\n",
    "print('Per-label F1:', {LABELS[i]: round(float(per_label_base[i]), 6) for i in range(len(LABELS))})\n",
    "\n",
    "rule_applied = False\n",
    "macro_after_rule = macro_base\n",
    "if ENABLE_NON_ESG_RULE:\n",
    "    oof_pred_rule = apply_non_esg_rule(oof_pred)\n",
    "    macro_rule, _ = macro_f1(y_true_int, oof_pred_rule)\n",
    "    print('Macro-F1 after non_ESG rule:', round(macro_rule, 6))\n",
    "    if macro_rule >= macro_base:\n",
    "        oof_pred = oof_pred_rule\n",
    "        test_pred = apply_non_esg_rule(test_pred)\n",
    "        macro_after_rule = macro_rule\n",
    "        rule_applied = True\n",
    "\n",
    "assert oof_prob.shape == (len(train_df), len(LABELS))\n",
    "assert test_prob.shape == (len(test_df), len(LABELS))\n",
    "assert set(thresholds.keys()) == set(LABELS)\n",
    "print('Validation checks passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d3f657",
   "metadata": {},
   "source": [
    "## 6) Visualize Key Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame({\n",
    "    'label': LABELS,\n",
    "    'prevalence': [float(prevalence[l]) for l in LABELS],\n",
    "    'threshold': [float(thresholds[l]) for l in LABELS],\n",
    "    'f1_oof': [float(per_label_base[i]) for i in range(len(LABELS))],\n",
    "}).sort_values('prevalence', ascending=False)\n",
    "\n",
    "print('Fold metrics @ threshold 0.5:')\n",
    "pd.DataFrame(fold_metrics)\n",
    "\n",
    "display(summary_df)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "summary_df.plot(kind='bar', x='label', y='prevalence', ax=axes[0], legend=False, title='Label Prevalence')\n",
    "summary_df.plot(kind='bar', x='label', y='threshold', ax=axes[1], legend=False, title='Tuned Thresholds')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dffae0",
   "metadata": {},
   "source": [
    "## 7) Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a62150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample_sub_df.copy()\n",
    "if ID_COL in submission.columns and ID_COL in test_df.columns:\n",
    "    submission[ID_COL] = test_df[ID_COL].values\n",
    "for i, label in enumerate(LABELS):\n",
    "    submission[label] = test_pred[:, i].astype(int)\n",
    "\n",
    "oof_prob_df = pd.DataFrame({ID_COL: train_df[ID_COL].values})\n",
    "for i, label in enumerate(LABELS):\n",
    "    oof_prob_df[f'{label}_prob'] = oof_prob[:, i]\n",
    "\n",
    "test_prob_df = pd.DataFrame({ID_COL: test_df[ID_COL].values})\n",
    "for i, label in enumerate(LABELS):\n",
    "    test_prob_df[f'{label}_prob'] = test_prob[:, i]\n",
    "\n",
    "report = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'labels': LABELS,\n",
    "    'prevalence': {k: float(v) for k, v in prevalence.to_dict().items()},\n",
    "    'thresholds': {k: float(v) for k, v in thresholds.items()},\n",
    "    'macro_f1_oof_threshold_tuned': float(macro_base),\n",
    "    'macro_f1_oof_after_optional_non_esg_rule': float(macro_after_rule),\n",
    "    'non_esg_rule_applied': bool(rule_applied),\n",
    "    'fold_metrics_default_threshold_0_5': fold_metrics,\n",
    "    'params': {\n",
    "        'n_splits': N_SPLITS,\n",
    "        'max_length': MAX_LENGTH,\n",
    "        'learning_rate': LR,\n",
    "        'train_batch_size': TRAIN_BS,\n",
    "        'eval_batch_size': EVAL_BS,\n",
    "        'num_epochs': NUM_EPOCHS,\n",
    "        'weight_decay': WEIGHT_DECAY,\n",
    "        'threshold_grid': [THRESHOLD_MIN, THRESHOLD_MAX, THRESHOLD_STEP],\n",
    "    },\n",
    "}\n",
    "\n",
    "submission_path = OUTPUT_DIR / 'submission_distilbert.csv'\n",
    "report_path = OUTPUT_DIR / 'distilbert_threshold_report.json'\n",
    "oof_path = OUTPUT_DIR / 'oof_probs_distilbert.csv'\n",
    "test_prob_path = OUTPUT_DIR / 'test_probs_distilbert.csv'\n",
    "\n",
    "submission.to_csv(submission_path, index=False)\n",
    "oof_prob_df.to_csv(oof_path, index=False)\n",
    "test_prob_df.to_csv(test_prob_path, index=False)\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print('Saved:')\n",
    "print(submission_path)\n",
    "print(report_path)\n",
    "print(oof_path)\n",
    "print(test_prob_path)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
