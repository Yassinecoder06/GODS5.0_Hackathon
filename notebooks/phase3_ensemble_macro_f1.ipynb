{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b9ce2e",
   "metadata": {},
   "source": [
    "# Phase 3: OOF Ensemble + Threshold Optimization (Macro-F1)\n",
    "\n",
    "This notebook blends model probabilities from:\n",
    "- DistilBERT outputs (`oof_probs_distilbert.csv`, `test_probs_distilbert.csv`)\n",
    "- TF-IDF + Logistic outputs (`oof_probs.csv`, `test_probs.csv`)\n",
    "\n",
    "Then it optimizes:\n",
    "1) blend weights (OOF),\n",
    "2) per-label thresholds,\n",
    "3) optional `non_ESG` consistency rule,\n",
    "and exports final submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a45068",
   "metadata": {},
   "source": [
    "## 1) Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd412e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e511a26d",
   "metadata": {},
   "source": [
    "## 2) Configure Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d80007",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['E', 'S', 'G', 'non_ESG']\n",
    "ID_COL = 'id'\n",
    "\n",
    "# Root detection\n",
    "if Path('data_set').exists():\n",
    "    ROOT = Path('.')\n",
    "elif Path('../data_set').exists():\n",
    "    ROOT = Path('..')\n",
    "else:\n",
    "    ROOT = Path('.')\n",
    "\n",
    "DATA_DIR = ROOT / 'data_set'\n",
    "OUT_DIR = ROOT / 'outputs'\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_PATH = DATA_DIR / 'train.csv'\n",
    "SAMPLE_SUB_PATH = DATA_DIR / 'sample_submission.csv'\n",
    "TEST_PATH = DATA_DIR / 'test.csv'\n",
    "\n",
    "OOF_BERT_PATH = OUT_DIR / 'oof_probs_distilbert.csv'\n",
    "TEST_BERT_PATH = OUT_DIR / 'test_probs_distilbert.csv'\n",
    "\n",
    "OOF_TFIDF_PATH = OUT_DIR / 'oof_probs.csv'\n",
    "TEST_TFIDF_PATH = OUT_DIR / 'test_probs.csv'\n",
    "\n",
    "ALPHA_GRID = np.round(np.arange(0.0, 1.0001, 0.05), 4)  # weight for DistilBERT\n",
    "THRESH_MIN, THRESH_MAX, THRESH_STEP = 0.05, 0.95, 0.01\n",
    "RULE_GRID = np.round(np.arange(0.30, 0.9001, 0.02), 4)  # max(E,S,G) threshold for non_ESG override\n",
    "ENABLE_RULE_SEARCH = True\n",
    "\n",
    "print('ROOT:', ROOT.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b307b",
   "metadata": {},
   "source": [
    "## 3) Load or Create Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [TRAIN_PATH, TEST_PATH, SAMPLE_SUB_PATH, OOF_BERT_PATH, TEST_BERT_PATH, OOF_TFIDF_PATH, TEST_TFIDF_PATH]:\n",
    "    print(f'{p}:', p.exists())\n",
    "\n",
    "assert TRAIN_PATH.exists(), 'Missing train.csv'\n",
    "assert TEST_PATH.exists(), 'Missing test.csv'\n",
    "assert SAMPLE_SUB_PATH.exists(), 'Missing sample_submission.csv'\n",
    "assert OOF_BERT_PATH.exists(), 'Missing outputs/oof_probs_distilbert.csv (run phase2 first)'\n",
    "assert TEST_BERT_PATH.exists(), 'Missing outputs/test_probs_distilbert.csv (run phase2 first)'\n",
    "assert OOF_TFIDF_PATH.exists(), 'Missing outputs/oof_probs.csv (run TF-IDF baseline first)'\n",
    "assert TEST_TFIDF_PATH.exists(), 'Missing outputs/test_probs.csv (run TF-IDF baseline first)'\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "sample_sub_df = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "\n",
    "y_true = train_df[LABELS].values.astype(int)\n",
    "\n",
    "oof_bert = pd.read_csv(OOF_BERT_PATH)\n",
    "test_bert = pd.read_csv(TEST_BERT_PATH)\n",
    "oof_tfidf = pd.read_csv(OOF_TFIDF_PATH)\n",
    "test_tfidf = pd.read_csv(TEST_TFIDF_PATH)\n",
    "\n",
    "# Align by id to avoid ordering mismatch\n",
    "if ID_COL in train_df.columns and ID_COL in oof_bert.columns and ID_COL in oof_tfidf.columns:\n",
    "    oof_bert = train_df[[ID_COL]].merge(oof_bert, on=ID_COL, how='left')\n",
    "    oof_tfidf = train_df[[ID_COL]].merge(oof_tfidf, on=ID_COL, how='left')\n",
    "\n",
    "if ID_COL in test_df.columns and ID_COL in test_bert.columns and ID_COL in test_tfidf.columns:\n",
    "    test_bert = test_df[[ID_COL]].merge(test_bert, on=ID_COL, how='left')\n",
    "    test_tfidf = test_df[[ID_COL]].merge(test_tfidf, on=ID_COL, how='left')\n",
    "\n",
    "for label in LABELS:\n",
    "    assert f'{label}_prob' in oof_bert.columns\n",
    "    assert f'{label}_prob' in oof_tfidf.columns\n",
    "    assert f'{label}_prob' in test_bert.columns\n",
    "    assert f'{label}_prob' in test_tfidf.columns\n",
    "\n",
    "oof_prob_bert = oof_bert[[f'{l}_prob' for l in LABELS]].values.astype(float)\n",
    "oof_prob_tfidf = oof_tfidf[[f'{l}_prob' for l in LABELS]].values.astype(float)\n",
    "test_prob_bert = test_bert[[f'{l}_prob' for l in LABELS]].values.astype(float)\n",
    "test_prob_tfidf = test_tfidf[[f'{l}_prob' for l in LABELS]].values.astype(float)\n",
    "\n",
    "print('Loaded OOF/Test probability matrices.')\n",
    "print('OOF shape:', oof_prob_bert.shape, 'Test shape:', test_prob_bert.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a0279",
   "metadata": {},
   "source": [
    "## 4) Implement Core Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a419b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(y_true, y_pred):\n",
    "    scores = [f1_score(y_true[:, i], y_pred[:, i], zero_division=0) for i in range(y_true.shape[1])]\n",
    "    return float(np.mean(scores)), scores\n",
    "\n",
    "\n",
    "def tune_thresholds(y_true, y_prob, tmin=0.05, tmax=0.95, step=0.01):\n",
    "    grid = np.arange(tmin, tmax + 1e-12, step)\n",
    "    best = {}\n",
    "    for i, label in enumerate(LABELS):\n",
    "        best_t, best_f1 = 0.5, -1.0\n",
    "        for t in grid:\n",
    "            pred = (y_prob[:, i] >= t).astype(int)\n",
    "            f1 = f1_score(y_true[:, i], pred, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_t = float(t)\n",
    "        best[label] = round(best_t, 4)\n",
    "    return best\n",
    "\n",
    "\n",
    "def apply_thresholds(y_prob, thresholds):\n",
    "    y_pred = np.zeros_like(y_prob, dtype=int)\n",
    "    for i, label in enumerate(LABELS):\n",
    "        y_pred[:, i] = (y_prob[:, i] >= thresholds[label]).astype(int)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def apply_non_esg_rule_with_confidence(prob_matrix, pred_matrix, trigger=0.5):\n",
    "    fixed = pred_matrix.copy()\n",
    "    esg_conf = prob_matrix[:, :3].max(axis=1)\n",
    "    fixed[esg_conf >= trigger, 3] = 0\n",
    "    return fixed\n",
    "\n",
    "\n",
    "# Step A: per-label alpha search (weight for DistilBERT)\n",
    "alpha_per_label = {}\n",
    "blended_oof = np.zeros_like(oof_prob_bert)\n",
    "blended_test = np.zeros_like(test_prob_bert)\n",
    "\n",
    "for i, label in enumerate(LABELS):\n",
    "    best_alpha, best_f1 = 0.5, -1.0\n",
    "    p_bert = oof_prob_bert[:, i]\n",
    "    p_tfidf = oof_prob_tfidf[:, i]\n",
    "    y_label = y_true[:, i]\n",
    "\n",
    "    for alpha in ALPHA_GRID:\n",
    "        p_blend = alpha * p_bert + (1.0 - alpha) * p_tfidf\n",
    "        pred = (p_blend >= 0.5).astype(int)\n",
    "        f1 = f1_score(y_label, pred, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_alpha = float(alpha)\n",
    "\n",
    "    alpha_per_label[label] = round(best_alpha, 4)\n",
    "    blended_oof[:, i] = best_alpha * oof_prob_bert[:, i] + (1.0 - best_alpha) * oof_prob_tfidf[:, i]\n",
    "    blended_test[:, i] = best_alpha * test_prob_bert[:, i] + (1.0 - best_alpha) * test_prob_tfidf[:, i]\n",
    "\n",
    "print('Best alpha per label (DistilBERT weight):', alpha_per_label)\n",
    "\n",
    "# Step B: threshold tuning on blended OOF probs\n",
    "thresholds = tune_thresholds(y_true, blended_oof, THRESH_MIN, THRESH_MAX, THRESH_STEP)\n",
    "oof_pred = apply_thresholds(blended_oof, thresholds)\n",
    "test_pred = apply_thresholds(blended_test, thresholds)\n",
    "\n",
    "macro_base, per_label_f1 = macro_f1(y_true, oof_pred)\n",
    "print('Macro-F1 after blend + thresholds:', round(macro_base, 6))\n",
    "\n",
    "# Step C: optional non_ESG rule search\n",
    "rule_applied = False\n",
    "best_rule_trigger = None\n",
    "macro_after_rule = macro_base\n",
    "\n",
    "if ENABLE_RULE_SEARCH:\n",
    "    best_score = macro_base\n",
    "    best_pred_oof = oof_pred\n",
    "    best_pred_test = test_pred\n",
    "\n",
    "    for trig in RULE_GRID:\n",
    "        cand_oof = apply_non_esg_rule_with_confidence(blended_oof, oof_pred, trigger=float(trig))\n",
    "        score, _ = macro_f1(y_true, cand_oof)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_rule_trigger = float(trig)\n",
    "            best_pred_oof = cand_oof\n",
    "            best_pred_test = apply_non_esg_rule_with_confidence(blended_test, test_pred, trigger=float(trig))\n",
    "\n",
    "    if best_score > macro_base:\n",
    "        rule_applied = True\n",
    "        macro_after_rule = best_score\n",
    "        oof_pred = best_pred_oof\n",
    "        test_pred = best_pred_test\n",
    "\n",
    "print('Rule applied:', rule_applied, '| best trigger:', best_rule_trigger)\n",
    "print('Final OOF macro-F1:', round(macro_after_rule, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793abba4",
   "metadata": {},
   "source": [
    "## 5) Run Validation Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82036b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert blended_oof.shape == (len(train_df), len(LABELS))\n",
    "assert blended_test.shape == (len(test_df), len(LABELS))\n",
    "assert set(alpha_per_label.keys()) == set(LABELS)\n",
    "assert set(thresholds.keys()) == set(LABELS)\n",
    "\n",
    "final_macro, final_label_scores = macro_f1(y_true, oof_pred)\n",
    "print('Checks passed.')\n",
    "print('Final macro-F1:', round(final_macro, 6))\n",
    "print('Final per-label F1:', {LABELS[i]: round(float(final_label_scores[i]), 6) for i in range(len(LABELS))})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81157eb6",
   "metadata": {},
   "source": [
    "## 6) Visualize Key Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame({\n",
    "    'label': LABELS,\n",
    "    'alpha_distilbert': [alpha_per_label[l] for l in LABELS],\n",
    "    'threshold': [thresholds[l] for l in LABELS],\n",
    "    'f1_oof': [float(final_label_scores[i]) for i in range(len(LABELS))],\n",
    "})\n",
    "\n",
    "display(summary_df)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "summary_df.plot(kind='bar', x='label', y='alpha_distilbert', ax=axes[0], legend=False, title='Blend Weights')\n",
    "summary_df.plot(kind='bar', x='label', y='threshold', ax=axes[1], legend=False, title='Tuned Thresholds')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da79a14a",
   "metadata": {},
   "source": [
    "## 7) Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample_sub_df.copy()\n",
    "if ID_COL in submission.columns and ID_COL in test_df.columns:\n",
    "    submission[ID_COL] = test_df[ID_COL].values\n",
    "\n",
    "for i, label in enumerate(LABELS):\n",
    "    submission[label] = test_pred[:, i].astype(int)\n",
    "\n",
    "oof_prob_out = pd.DataFrame({ID_COL: train_df[ID_COL].values}) if ID_COL in train_df.columns else pd.DataFrame(index=np.arange(len(train_df)))\n",
    "test_prob_out = pd.DataFrame({ID_COL: test_df[ID_COL].values}) if ID_COL in test_df.columns else pd.DataFrame(index=np.arange(len(test_df)))\n",
    "for i, label in enumerate(LABELS):\n",
    "    oof_prob_out[f'{label}_prob'] = blended_oof[:, i]\n",
    "    test_prob_out[f'{label}_prob'] = blended_test[:, i]\n",
    "\n",
    "report = {\n",
    "    'labels': LABELS,\n",
    "    'alpha_per_label_distilbert_weight': {k: float(v) for k, v in alpha_per_label.items()},\n",
    "    'thresholds': {k: float(v) for k, v in thresholds.items()},\n",
    "    'macro_f1_oof_before_rule': float(macro_base),\n",
    "    'macro_f1_oof_final': float(final_macro),\n",
    "    'per_label_f1_oof_final': {LABELS[i]: float(final_label_scores[i]) for i in range(len(LABELS))},\n",
    "    'non_esg_rule_applied': bool(rule_applied),\n",
    "    'non_esg_rule_trigger': None if best_rule_trigger is None else float(best_rule_trigger),\n",
    "    'search': {\n",
    "        'alpha_grid': [float(a) for a in ALPHA_GRID.tolist()],\n",
    "        'threshold_grid': [THRESH_MIN, THRESH_MAX, THRESH_STEP],\n",
    "        'rule_grid': [float(r) for r in RULE_GRID.tolist()] if ENABLE_RULE_SEARCH else None,\n",
    "    },\n",
    "    'sources': {\n",
    "        'oof_distilbert': str(OOF_BERT_PATH),\n",
    "        'oof_tfidf': str(OOF_TFIDF_PATH),\n",
    "        'test_distilbert': str(TEST_BERT_PATH),\n",
    "        'test_tfidf': str(TEST_TFIDF_PATH),\n",
    "    },\n",
    "}\n",
    "\n",
    "submission_path = OUT_DIR / 'submission_ensemble_phase3.csv'\n",
    "report_path = OUT_DIR / 'ensemble_phase3_report.json'\n",
    "oof_path = OUT_DIR / 'oof_probs_ensemble_phase3.csv'\n",
    "test_prob_path = OUT_DIR / 'test_probs_ensemble_phase3.csv'\n",
    "\n",
    "submission.to_csv(submission_path, index=False)\n",
    "oof_prob_out.to_csv(oof_path, index=False)\n",
    "test_prob_out.to_csv(test_prob_path, index=False)\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print('Saved:')\n",
    "print(submission_path)\n",
    "print(report_path)\n",
    "print(oof_path)\n",
    "print(test_prob_path)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
